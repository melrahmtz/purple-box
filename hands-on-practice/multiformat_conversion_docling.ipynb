{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melrahmtz/purple-box/blob/main/hands-on-practice/multiformat_conversion_docling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "AZVStY6ucfAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "_log = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "lsaVBVLBccrG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU or MPS is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"CUDA GPU is enabled: {torch.cuda.get_device_name(0)}\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"MPS GPU is enabled.\")\n",
        "else:\n",
        "    raise EnvironmentError(\n",
        "        \"No GPU or MPS device found. Please check your environment and ensure GPU or MPS support is configured.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "WEztRrOgci3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "obLbuBHhclCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index>=0.12.8 llama-index-core>=0.12.8\n",
        "!pip install llama-index-node-parser-docling>=0.3.0 llama-index-readers-docling>=0.3.0\n",
        "!pip install pypdf2>=3.0.1\n",
        "!pip install easyocr>=1.7.2\n",
        "\n",
        "#!pip install ipykernel>=6.29.5\n",
        "# !pip install llama-index-embeddings-ollama>=0.5.0 llama-index-embeddings-huggingface>=0.4.0\n",
        "# !pip install llama-index-llms-huggingface-api>=0.3.0 llama-index-llms-ollama>=0.5.0\n",
        "# !pip install llama-index-readers-file>=0.4.1\n",
        "# !pip install llama-index-vector-stores-milvus>=0.4.0\n",
        "# !pip install python-dotenv>=1.0.1\n",
        "# !pip install rich>=13.9.4\n",
        "# !pip install pillow>=10.4.0\n",
        "# !pip install pyarrow>=18.1.0\n",
        "# !pip install fastparquet>=2024.11.0\n",
        "# !pip install datasets>=3.2.0\n",
        "# #!pip install ocrmac>=1.0.0\n",
        "# !pip install matplotlib>=3.10.0\n",
        "# !pip install toml>=0.10.2"
      ],
      "metadata": {
        "id": "ABJJtlyCcoiz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Data"
      ],
      "metadata": {
        "id": "GZGKVFesdSDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English Files\n",
        "# Upload all the files to Google Colab Files. The code below will create a directory called 'data' and move the files to it.\n",
        "!mkdir -p data\n",
        "\n",
        "!mv 17.pdf data/17.pdf\n",
        "!mv 2014_monarch_plus_service_manual.pdf data/2014_monarch_plus_service_manual.pdf\n",
        "!mv 2024_11_05_Ferrari_Q3_2024_Results_Press_Release.pdf data/2024_11_05_Ferrari_Q3_2024_Results_Press_Release.pdf\n",
        "!mv 231161_OperationsMaintenanceManual.docx data/231161_OperationsMaintenanceManual.docx\n",
        "!mv PDF1.pdf data/PDF1.pdf\n",
        "!mv SUPO-744_REV_A.pdf data/SUPO-744_REV_A.pdf\n",
        "!mv Test-OCR-Handwritten.jpg data/Test-OCR-Handwritten.jpg\n",
        "!mv VVS005s_030s_AHU_EN.pdf data/VVS005s_030s_AHU_EN.pdf\n",
        "!mv ai-in-america-oai-economic-blueprint-20250113.pdf data/ai-in-america-oai-economic-blueprint-20250113.pdf\n",
        "!mv creatingsystem.pdf data/creatingsystem.pdf\n",
        "!mv image1.png data/image1.png\n",
        "!mv monarch_exploded_view.png data/monarch_exploded_view.png"
      ],
      "metadata": {
        "id": "EIZbpsX7dZeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d834a65-177d-403e-9020-0d5928d53f63"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '17.pdf': No such file or directory\n",
            "mv: cannot stat '2014_monarch_plus_service_manual.pdf': No such file or directory\n",
            "mv: cannot stat '2024_11_05_Ferrari_Q3_2024_Results_Press_Release.pdf': No such file or directory\n",
            "mv: cannot stat '231161_OperationsMaintenanceManual.docx': No such file or directory\n",
            "mv: cannot stat 'PDF1.pdf': No such file or directory\n",
            "mv: cannot stat 'SUPO-744_REV_A.pdf': No such file or directory\n",
            "mv: cannot stat 'Test-OCR-Handwritten.jpg': No such file or directory\n",
            "mv: cannot stat 'VVS005s_030s_AHU_EN.pdf': No such file or directory\n",
            "mv: cannot stat 'ai-in-america-oai-economic-blueprint-20250113.pdf': No such file or directory\n",
            "mv: cannot stat 'creatingsystem.pdf': No such file or directory\n",
            "mv: cannot stat 'image1.png': No such file or directory\n",
            "mv: cannot stat 'monarch_exploded_view.png': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Docling Conversion"
      ],
      "metadata": {
        "id": "PUa2m4EfdaBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling_core.types.doc import ImageRefMode\n",
        "from docling.document_converter import DocumentConverter, PdfFormatOption, WordFormatOption\n",
        "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend  # Import the backend\n",
        "from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline # Import the Pipeline\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode, EasyOcrOptions, TesseractOcrOptions, OcrMacOptions\n",
        "from docling.pipeline.simple_pipeline import SimplePipeline\n",
        "from docling.datamodel.settings import settings\n",
        "\n",
        "IMAGE_RESOLUTION_SCALE = 2.0\n",
        "\n",
        "def create_pipeline_options(input_format):\n",
        "    \"\"\"Creates dynamic pipeline options based on the input format.\"\"\"\n",
        "    if input_format == InputFormat.PDF:\n",
        "\n",
        "        return PdfFormatOption(\n",
        "            pipeline_options = PdfPipelineOptions(\n",
        "                do_table_structure=True,  # Enable table structure detection\n",
        "                # do_ocr=True,  # Enable OCR\n",
        "                # ocr_options=EasyOcrOptions(force_full_page_ocr=True, lang=[\"en\"]),\n",
        "                # table_structure_option=dict(\n",
        "                #     do_cell_matching=True,\n",
        "                #     mode=TableFormerMode.ACCURATE\n",
        "                # ),\n",
        "                generate_page_images=True,\n",
        "                generate_picture_images=True,\n",
        "                image_mode=ImageRefMode.EMBEDDED,  # or ImageRefMode.REFERENCED\n",
        "                images_scale=IMAGE_RESOLUTION_SCALE,\n",
        "            )\n",
        "\n",
        "            # pipeline_cls=StandardPdfPipeline,  # Specify the pipeline class\n",
        "            # backend=PyPdfiumDocumentBackend,  # Specify the backend explicitly\n",
        "            # do_table_structure=True,  # Enable table structure detection\n",
        "\n",
        "            # generate_page_images=True,\n",
        "            # generate_picture_images=True,\n",
        "            # image_mode=ImageRefMode.EMBEDDED,  # or ImageRefMode.REFERENCED\n",
        "            # images_scale=IMAGE_RESOLUTION_SCALE,\n",
        "        )\n",
        "\n",
        "    elif input_format == InputFormat.DOCX:\n",
        "        return WordFormatOption(\n",
        "            pipeline_cls=SimplePipeline  # Configure Word document pipeline\n",
        "        )\n",
        "\n",
        "    elif input_format == InputFormat.IMAGE:\n",
        "        return None  # Add image-specific options if needed\n",
        "    elif input_format == InputFormat.HTML:\n",
        "        return None  # Add HTML-specific options if needed\n",
        "    elif input_format == InputFormat.PPTX:\n",
        "        return None  # Add PowerPoint-specific options if needed\n",
        "    elif input_format == InputFormat.ASCIIDOC or input_format == InputFormat.MD:\n",
        "        return None  # These formats might not need advanced options\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported input format: {input_format}\")"
      ],
      "metadata": {
        "id": "0HAEbWuVdgH_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "\n",
        "def initialize_converter():\n",
        "    \"\"\"Initializes the document converter with multiformat support and advanced options.\"\"\"\n",
        "    allowed_formats = [\n",
        "        InputFormat.PDF,\n",
        "        InputFormat.IMAGE,\n",
        "        InputFormat.DOCX,\n",
        "        InputFormat.HTML,\n",
        "        InputFormat.PPTX,\n",
        "        InputFormat.ASCIIDOC,\n",
        "        InputFormat.MD,\n",
        "    ]\n",
        "\n",
        "    format_options = {\n",
        "        input_format: create_pipeline_options(input_format)\n",
        "        for input_format in allowed_formats\n",
        "        if create_pipeline_options(input_format) is not None\n",
        "    }\n",
        "\n",
        "    return DocumentConverter(\n",
        "        allowed_formats=allowed_formats,\n",
        "        format_options=format_options,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "DxQdoI8V3sML"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import yaml\n",
        "\n",
        "def convert_and_save(input_paths, output_dir, image_mode=ImageRefMode.REFERENCED):\n",
        "    \"\"\"Converts documents to Markdown and saves the output.\"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    doc_converter = initialize_converter()\n",
        "    conv_results = doc_converter.convert_all(input_paths)\n",
        "\n",
        "    for res in conv_results:\n",
        "        file_name = res.input.file.stem\n",
        "        markdown_path = output_dir / f\"{file_name}.md\"\n",
        "        json_path = output_dir / f\"{file_name}.json\"\n",
        "        yaml_path = output_dir / f\"{file_name}.yaml\"\n",
        "\n",
        "        # Save Markdown output\n",
        "        res.document.save_as_markdown(markdown_path, image_mode=image_mode)\n",
        "        _log.info(f\"Markdown content saved to {markdown_path}\")\n",
        "\n",
        "        # # Save JSON output\n",
        "        # with json_path.open(\"w\") as fp:\n",
        "        #     fp.write(json.dumps(res.document.export_to_dict(), indent=4))\n",
        "        # _log.info(f\"JSON content saved to {json_path}\")\n",
        "\n",
        "        # # Save YAML output\n",
        "        # with yaml_path.open(\"w\") as fp:\n",
        "        #     fp.write(yaml.safe_dump(res.document.export_to_dict()))\n",
        "        # _log.info(f\"YAML content saved to {yaml_path}\")\n"
      ],
      "metadata": {
        "id": "rX6rv8sR3zbj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nodes Extraction"
      ],
      "metadata": {
        "id": "Q9v_NUJJCj5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import MarkdownNodeParser\n",
        "from llama_index.readers.docling import DoclingReader\n",
        "\n",
        "def extract_nodes(file_path, output_dir):\n",
        "    \"\"\"Extracts nodes from the given document and saves them to a file.\"\"\"\n",
        "\n",
        "    doc_converter = initialize_converter()\n",
        "    reader = DoclingReader(DocumentConverter=doc_converter)\n",
        "    node_parser = MarkdownNodeParser()\n",
        "\n",
        "    documents = reader.load_data(file_path)\n",
        "    nodes = node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "    output_path = Path(output_dir) / f\"{file_path.stem}_nodes.json\"\n",
        "    extracted_data = {\n",
        "        \"file_name\": file_path.name,\n",
        "        \"number_of_nodes\": len(nodes),\n",
        "        \"nodes\": [\n",
        "            {\n",
        "                \"index\": index + 1,\n",
        "                \"text\": node.text,\n",
        "                \"metadata\": node.metadata\n",
        "            }\n",
        "            for index, node in enumerate(nodes)\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    with output_path.open(\"w\") as fp:\n",
        "        json.dump(extracted_data, fp, indent=4)\n",
        "\n",
        "    _log.info(f\"Extracted {len(nodes)} nodes from {file_path.name} and saved to {output_path}\")\n"
      ],
      "metadata": {
        "id": "Xn9gIVryZWeM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    settings.debug.profile_pipeline_timings = True\n",
        "\n",
        "    input_paths = [\n",
        "        Path(\"data/17.pdf\"),\n",
        "        Path(\"data/2024_11_05_Ferrari_Q3_2024_Results_Press_Release.pdf\"),\n",
        "        Path(\"data/231161_OperationsMaintenanceManual.docx\"),\n",
        "        Path(\"data/PDF1.pdf\"),\n",
        "        Path(\"data/SUPO-744_REV_A.pdf\"),\n",
        "        Path(\"data/ai-in-america-oai-economic-blueprint-20250113.pdf\"),\n",
        "        Path(\"data/creatingsystem.pdf\"),\n",
        "        Path(\"data/image1.png\"),\n",
        "        Path(\"data/Test-OCR-Handwritten.jpg\"),\n",
        "        Path(\"/content/sample_data/README.md\"),\n",
        "    ]\n",
        "\n",
        "    output_dir = \"output-docs\"\n",
        "    convert_and_save(input_paths, output_dir)\n",
        "\n",
        "    for file_path in input_paths:\n",
        "        extract_nodes(file_path, output_dir)\n"
      ],
      "metadata": {
        "id": "OlRHbgAa31P5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "G5EMlEyI34so"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding and Chunking"
      ],
      "metadata": {
        "id": "qL9zhnWndunU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trial from RAW Code"
      ],
      "metadata": {
        "id": "YJzGBljPcYuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QD1SfNZFyCN"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-node-parser-docling>=0.3.0 llama-index-readers-docling>=0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3d9Pt4Uv8uY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "import yaml\n",
        "\n",
        "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.document_converter import (\n",
        "    DocumentConverter,\n",
        "    PdfFormatOption,\n",
        "    WordFormatOption,\n",
        ")\n",
        "from docling.pipeline.simple_pipeline import SimplePipeline\n",
        "from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n",
        "\n",
        "_log = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AyeZVE3GsYw"
      },
      "outputs": [],
      "source": [
        "# English Files\n",
        "!mkdir -p data\n",
        "\n",
        "!mv 17.pdf data/17.pdf\n",
        "!mv 2014_monarch_plus_service_manual.pdf data/2014_monarch_plus_service_manual.pdf\n",
        "!mv 2024_11_05_Ferrari_Q3_2024_Results_Press_Release.pdf data/2024_11_05_Ferrari_Q3_2024_Results_Press_Release.pdf\n",
        "!mv 231161_OperationsMaintenanceManual.docx data/231161_OperationsMaintenanceManual.docx\n",
        "!mv PDF1.pdf data/PDF1.pdf\n",
        "!mv SUPO-744_REV_A.pdf data/SUPO-744_REV_A.pdf\n",
        "!mv Test-OCR-Handwritten.jpg data/Test-OCR-Handwritten.jpg\n",
        "!mv VVS005s_030s_AHU_EN.pdf data/VVS005s_030s_AHU_EN.pdf\n",
        "!mv ai-in-america-oai-economic-blueprint-20250113.pdf data/ai-in-america-oai-economic-blueprint-20250113.pdf\n",
        "!mv creatingsystem.pdf data/creatingsystem.pdf\n",
        "!mv image1.png data/image1.png\n",
        "!mv monarch_exploded_view.png data/monarch_exploded_view.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBFNZSA1_ORp"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    input_paths = [\n",
        "        # Path(\"data/17.pdf\"),\n",
        "        # Path(\"data/2024_11_05_Ferrari_Q3_2024_Results_Press_Release.pdf\"),\n",
        "        # Path(\"data/231161_OperationsMaintenanceManual.docx\"),\n",
        "        # Path(\"data/PDF1.pdf\"),\n",
        "        # Path(\"data/SUPO-744_REV_A.pdf\"),\n",
        "        # Path(\"data/ai-in-america-oai-economic-blueprint-20250113.pdf\"),\n",
        "        # Path(\"data/creatingsystem.pdf\"),\n",
        "        Path(\"data/image1.png\"),\n",
        "        Path(\"data/Test-OCR-Handwritten.jpg\"),\n",
        "        Path(\"/content/sample_data/README.md\"),\n",
        "    ]\n",
        "\n",
        "    doc_converter = (\n",
        "        DocumentConverter(  # all of the below is optional, has internal defaults.\n",
        "            allowed_formats=[\n",
        "                InputFormat.PDF,\n",
        "                InputFormat.IMAGE,\n",
        "                InputFormat.DOCX,\n",
        "                InputFormat.HTML,\n",
        "                InputFormat.PPTX,\n",
        "                InputFormat.ASCIIDOC,\n",
        "                InputFormat.MD,\n",
        "            ],  # whitelist formats, non-matching files are ignored.\n",
        "            format_options={\n",
        "                InputFormat.PDF: PdfFormatOption(\n",
        "                    pipeline_cls=StandardPdfPipeline, backend=PyPdfiumDocumentBackend\n",
        "                ),\n",
        "                InputFormat.DOCX: WordFormatOption(\n",
        "                    pipeline_cls=SimplePipeline  # , backend=MsWordDocumentBackend\n",
        "                ),\n",
        "            },\n",
        "        )\n",
        "    )\n",
        "\n",
        "    conv_results = doc_converter.convert_all(input_paths)\n",
        "\n",
        "    for res in conv_results:\n",
        "        out_path = Path(\"scratch\")\n",
        "        out_path.mkdir(parents=True, exist_ok=True)\n",
        "        print(\n",
        "            f\"Document {res.input.file.name} converted.\"\n",
        "            f\"\\nSaved markdown output to: {str(out_path)}\"\n",
        "        )\n",
        "        _log.debug(res.document._export_to_indented_text(max_text_len=16))\n",
        "        # Export Docling document format to markdowndoc:\n",
        "        with (out_path / f\"{res.input.file.stem}.md\").open(\"w\") as fp:\n",
        "            fp.write(res.document.export_to_markdown())\n",
        "\n",
        "        with (out_path / f\"{res.input.file.stem}.json\").open(\"w\") as fp:\n",
        "            fp.write(json.dumps(res.document.export_to_dict()))\n",
        "\n",
        "        with (out_path / f\"{res.input.file.stem}.yaml\").open(\"w\") as fp:\n",
        "            fp.write(yaml.safe_dump(res.document.export_to_dict()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e29JSWXGMYm",
        "outputId": "a011291b-ecdb-4bef-c33c-4402361560d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document image1.png converted.\n",
            "Saved markdown output to: scratch\n",
            "Document Test-OCR-Handwritten.jpg converted.\n",
            "Saved markdown output to: scratch\n",
            "Document README.md converted.\n",
            "Saved markdown output to: scratch\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO28xc4dRIuD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kXorSbFVdgay"
      ],
      "authorship_tag": "ABX9TyPSL3ZFkC7GTnYFi00l2iY8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}